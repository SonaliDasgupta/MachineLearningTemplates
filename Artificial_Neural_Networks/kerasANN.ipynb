{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: np_utils in ./.local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: future>=0.16 in /usr/local/lib/python2.7/dist-packages (from np_utils)\n",
      "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python2.7/site-packages (from np_utils)\n",
      "Requirement already satisfied: mkl-random in /usr/local/lib/python2.7/dist-packages (from numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: mkl-fft in /usr/local/lib/python2.7/dist-packages (from numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python2.7/dist-packages (from numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python2.7/dist-packages (from numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: icc-rt in /usr/local/lib/python2.7/dist-packages (from numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: intel-numpy in /usr/local/lib/python2.7/dist-packages (from mkl-random->numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python2.7/dist-packages (from mkl->numpy>=1.0->np_utils)\n",
      "Requirement already satisfied: tbb==2019.* in /usr/local/lib/python2.7/dist-packages (from tbb4py->numpy>=1.0->np_utils)\n"
     ]
    }
   ],
   "source": [
    "!pip install np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in ./.local/lib/python2.7/site-packages\n",
      "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from kaggle)\n",
      "Requirement already satisfied: urllib3<1.23.0,>=1.15 in ./.local/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python2.7/dist-packages (from kaggle)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python2.7/dist-packages (from kaggle)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python2.7/dist-packages (from kaggle)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python2.7/dist-packages (from kaggle)\n",
      "Requirement already satisfied: python-slugify in ./.local/lib/python2.7/site-packages (from kaggle)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->kaggle)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->kaggle)\n",
      "Requirement already satisfied: Unidecode>=0.04.16 in ./.local/lib/python2.7/site-packages (from python-slugify->kaggle)\n",
      "/bin/sh: 1: kaggle: not found\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!kaggle competitions download -c petfinder-adoption-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Churn_Modelling.csv')\n",
    "X = data.iloc[:, 3:13]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance',\n",
       "       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from collections import defaultdict\n",
    "\n",
    "possDummyVals = defaultdict(set)\n",
    "\n",
    "        \n",
    "\n",
    "def addDummies(df, cols_for_dummies):\n",
    "    for col in cols_for_dummies:\n",
    "\n",
    "        df_col = pd.get_dummies(df[col], prefix = col, drop_first = True)\n",
    "        possDummyVals[col] = set(df_col.columns)\n",
    "        print('now possDummyVal for '+col+' : '+str(possDummyVals[col]))\n",
    "        print('num of dummies: '+str(len(df_col.columns)))\n",
    "        df = pd.concat([df, df_col], axis = 1)\n",
    "        print(\"added dummy for \"+col)\n",
    "        df.drop([col], axis = 1, inplace = True)\n",
    "        print('num of cols in df: '+str(len(df.columns)))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    le = LabelEncoder()    \n",
    "    df['Gender'] = le.fit_transform(df['Gender'])\n",
    "    cols_for_dummies = ['Geography', 'NumOfProducts', 'Tenure']\n",
    "    if len(df)==1:\n",
    "        return encodeSingle(df, cols_for_dummies)\n",
    "    return addDummies(df, cols_for_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeSingle(df, cols_for_dummies):\n",
    "    for col in cols_for_dummies:\n",
    "        val_col = df[col][0]\n",
    "        print(col+\"_\"+str(val_col))\n",
    "        print('set '+ col+\"_\"+str(val_col) + 'to 1')\n",
    "        print('num of cols: '+str(len(df.columns)))\n",
    "        possible_vals = [val for val in possDummyVals[col] if val != val_col]\n",
    "        print('other vals: '+str(possible_vals))\n",
    "        for cat_val in possible_vals:\n",
    "            if cat_val == str(col+\"_\"+str(val_col)):\n",
    "                df[cat_val] = 1\n",
    "            else:\n",
    "                df[cat_val] = 0\n",
    "        print('set other '+str(len(possible_vals)) + 'to 0')\n",
    "        print('num of cols: '+str(len(df.columns)))\n",
    "        df.drop([col], axis = 1, inplace = True)\n",
    "        print('encoded: '+col+ ' now num of cols: '+str(len(df.columns)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now possDummyVal for Geography : {'Geography_Spain', 'Geography_Germany'}\n",
      "num of dummies: 2\n",
      "added dummy for Geography\n",
      "num of cols in df: 11\n",
      "now possDummyVal for NumOfProducts : {'NumOfProducts_2', 'NumOfProducts_4', 'NumOfProducts_3'}\n",
      "num of dummies: 3\n",
      "added dummy for NumOfProducts\n",
      "num of cols in df: 13\n",
      "now possDummyVal for Tenure : {'Tenure_8', 'Tenure_7', 'Tenure_3', 'Tenure_2', 'Tenure_9', 'Tenure_6', 'Tenure_10', 'Tenure_4', 'Tenure_5', 'Tenure_1'}\n",
      "num of dummies: 10\n",
      "added dummy for Tenure\n",
      "num of cols in df: 22\n"
     ]
    }
   ],
   "source": [
    "X = preprocess(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "num_cols = ['CreditScore', 'Balance', 'EstimatedSalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train[num_cols] = sc.fit_transform(X_train[num_cols])\n",
    "X_val[num_cols] = sc.transform(X_val[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_temp = y_train.copy()\n",
    "y_val_temp = y_val.copy()\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the Keras model\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=22, units=12, kernel_initializer=\"uniform\", activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#adding dense layers\n",
    "classifier.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu', input_dim = 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=12, kernel_initializer=\"uniform\", activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifier.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=12, kernel_initializer=\"uniform\", activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 12, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=2, kernel_initializer=\"uniform\", activation=\"sigmoid\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 2, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=10,\n",
    "                              verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the ANN\n",
    "from keras.optimizers import Adam\n",
    "adam = Adam(lr = 1e-2)\n",
    "classifier.compile(optimizer = adam, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/100\n",
      "6400/6400 [==============================] - 3s 395us/step - loss: 0.4676 - acc: 0.7909 - val_loss: 0.3828 - val_acc: 0.8063\n",
      "Epoch 2/100\n",
      "6400/6400 [==============================] - 2s 244us/step - loss: 0.4189 - acc: 0.8034 - val_loss: 0.3933 - val_acc: 0.8281\n",
      "Epoch 3/100\n",
      "6400/6400 [==============================] - 2s 245us/step - loss: 0.4115 - acc: 0.8189 - val_loss: 0.3834 - val_acc: 0.8300\n",
      "Epoch 4/100\n",
      "6400/6400 [==============================] - 2s 251us/step - loss: 0.4075 - acc: 0.8215 - val_loss: 0.3628 - val_acc: 0.8438\n",
      "Epoch 5/100\n",
      "6400/6400 [==============================] - 2s 255us/step - loss: 0.3992 - acc: 0.8295 - val_loss: 0.3684 - val_acc: 0.8350\n",
      "Epoch 6/100\n",
      "6400/6400 [==============================] - 2s 237us/step - loss: 0.3981 - acc: 0.8266 - val_loss: 0.3639 - val_acc: 0.8419\n",
      "Epoch 7/100\n",
      "6400/6400 [==============================] - 2s 241us/step - loss: 0.3969 - acc: 0.8351 - val_loss: 0.3586 - val_acc: 0.8469\n",
      "Epoch 8/100\n",
      "6400/6400 [==============================] - 2s 242us/step - loss: 0.4023 - acc: 0.8319 - val_loss: 0.3678 - val_acc: 0.8456\n",
      "Epoch 9/100\n",
      "6400/6400 [==============================] - 2s 241us/step - loss: 0.3941 - acc: 0.8395 - val_loss: 0.3607 - val_acc: 0.8444\n",
      "Epoch 10/100\n",
      "6400/6400 [==============================] - 2s 246us/step - loss: 0.3931 - acc: 0.8317 - val_loss: 0.3607 - val_acc: 0.8438\n",
      "Epoch 11/100\n",
      "6400/6400 [==============================] - 2s 237us/step - loss: 0.3914 - acc: 0.8355 - val_loss: 0.3645 - val_acc: 0.8531\n",
      "Epoch 12/100\n",
      "6400/6400 [==============================] - 2s 244us/step - loss: 0.3903 - acc: 0.8361 - val_loss: 0.3546 - val_acc: 0.8513\n",
      "Epoch 13/100\n",
      "6400/6400 [==============================] - 2s 246us/step - loss: 0.3900 - acc: 0.8355 - val_loss: 0.3558 - val_acc: 0.8494\n",
      "Epoch 14/100\n",
      "6400/6400 [==============================] - 2s 243us/step - loss: 0.3865 - acc: 0.8356 - val_loss: 0.3659 - val_acc: 0.8481\n",
      "Epoch 15/100\n",
      "6400/6400 [==============================] - 2s 243us/step - loss: 0.3896 - acc: 0.8356 - val_loss: 0.3629 - val_acc: 0.8413\n",
      "Epoch 16/100\n",
      "6400/6400 [==============================] - 2s 238us/step - loss: 0.3837 - acc: 0.8403 - val_loss: 0.3562 - val_acc: 0.8447\n",
      "Epoch 17/100\n",
      "6400/6400 [==============================] - 2s 244us/step - loss: 0.3846 - acc: 0.8411 - val_loss: 0.3803 - val_acc: 0.8375\n",
      "Epoch 18/100\n",
      "6400/6400 [==============================] - 2s 250us/step - loss: 0.3837 - acc: 0.8384 - val_loss: 0.3603 - val_acc: 0.8547\n",
      "Epoch 19/100\n",
      "6400/6400 [==============================] - 2s 248us/step - loss: 0.3833 - acc: 0.8377 - val_loss: 0.3596 - val_acc: 0.8350\n",
      "Epoch 20/100\n",
      "6400/6400 [==============================] - 2s 244us/step - loss: 0.3858 - acc: 0.8387 - val_loss: 0.3610 - val_acc: 0.8413\n",
      "Epoch 21/100\n",
      "6400/6400 [==============================] - 2s 250us/step - loss: 0.3832 - acc: 0.8362 - val_loss: 0.3558 - val_acc: 0.8509\n",
      "Epoch 22/100\n",
      "6400/6400 [==============================] - 2s 240us/step - loss: 0.3859 - acc: 0.8364 - val_loss: 0.3543 - val_acc: 0.8550\n",
      "Epoch 23/100\n",
      "6400/6400 [==============================] - 2s 249us/step - loss: 0.3801 - acc: 0.8389 - val_loss: 0.3554 - val_acc: 0.8475\n",
      "Epoch 24/100\n",
      "6400/6400 [==============================] - 2s 249us/step - loss: 0.3799 - acc: 0.8396 - val_loss: 0.3482 - val_acc: 0.8513\n",
      "Epoch 25/100\n",
      "6400/6400 [==============================] - 2s 246us/step - loss: 0.3821 - acc: 0.8427 - val_loss: 0.3515 - val_acc: 0.8519\n",
      "Epoch 26/100\n",
      "6400/6400 [==============================] - 2s 260us/step - loss: 0.3797 - acc: 0.8418 - val_loss: 0.3480 - val_acc: 0.8547\n",
      "Epoch 27/100\n",
      "6400/6400 [==============================] - 1s 232us/step - loss: 0.3786 - acc: 0.8448 - val_loss: 0.3901 - val_acc: 0.8394\n",
      "Epoch 28/100\n",
      "6400/6400 [==============================] - 2s 236us/step - loss: 0.3767 - acc: 0.8424 - val_loss: 0.3582 - val_acc: 0.8419\n",
      "Epoch 29/100\n",
      "6400/6400 [==============================] - 1s 226us/step - loss: 0.3754 - acc: 0.8445 - val_loss: 0.3522 - val_acc: 0.8550\n",
      "Epoch 30/100\n",
      "6400/6400 [==============================] - 2s 235us/step - loss: 0.3768 - acc: 0.8463 - val_loss: 0.3648 - val_acc: 0.8503\n",
      "Epoch 31/100\n",
      "6400/6400 [==============================] - 2s 256us/step - loss: 0.3753 - acc: 0.8434 - val_loss: 0.3621 - val_acc: 0.8469\n",
      "Epoch 32/100\n",
      "6400/6400 [==============================] - 2s 244us/step - loss: 0.3723 - acc: 0.8447 - val_loss: 0.3528 - val_acc: 0.8450\n",
      "Epoch 33/100\n",
      "6400/6400 [==============================] - 1s 223us/step - loss: 0.3721 - acc: 0.8425 - val_loss: 0.3520 - val_acc: 0.8538\n",
      "Epoch 34/100\n",
      "6400/6400 [==============================] - 2s 237us/step - loss: 0.3759 - acc: 0.8398 - val_loss: 0.3650 - val_acc: 0.8356\n",
      "Epoch 35/100\n",
      "6400/6400 [==============================] - 2s 240us/step - loss: 0.3755 - acc: 0.8393 - val_loss: 0.3769 - val_acc: 0.8331\n",
      "Epoch 36/100\n",
      "6400/6400 [==============================] - 2s 236us/step - loss: 0.3766 - acc: 0.8418 - val_loss: 0.3564 - val_acc: 0.8419\n",
      "Epoch 00036: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7fa4d46e80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training \n",
    "from sklearn.utils import compute_class_weight\n",
    "class_weights = compute_class_weight('balanced', [0, 1], y_train_temp)\n",
    "classifier.fit(X_train, y_train, batch_size = 20, nb_epoch = 100, callbacks = callbacks, validation_split = 0.2, class_weight = class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that model has been trained to 85% accuracy , start with test/validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 59us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37075501108169556, 0.84475]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict_classes(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_val_temp, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1578,   29],\n",
       "       [ 281,  112]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1578+112)/(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1578,   29],\n",
       "       [ 282,  111]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict(X_val)\n",
    "y_pred1 = (y_pred_prob[:, 1] > 0.5)\n",
    "cm1 = confusion_matrix(y_val_temp, y_pred1)\n",
    "cm1\n",
    "\n",
    "#IMP: CAN SET CONFIDENCE THIS WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8535"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1543+164)/(1543+164+235+58) #accuracy is calculated using this 0.5 confidence method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []\n",
    "row_dict = {'Geography': 'France', 'CreditScore': 600, 'Gender': 'Male', 'Age': 40, 'Tenure': 3, 'Balance': 60000, 'NumOfProducts': 2, 'HasCrCard': 1, 'IsActiveMember': 1, 'EstimatedSalary': 50000}\n",
    "rows_list.append(row_dict)\n",
    "test_df = pd.DataFrame(rows_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Balance', 'CreditScore', 'EstimatedSalary', 'Gender',\n",
       "       'Geography', 'HasCrCard', 'IsActiveMember', 'NumOfProducts', 'Tenure'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geography_France\n",
      "set Geography_Franceto 1\n",
      "num of cols: 10\n",
      "other vals: ['Geography_Spain', 'Geography_Germany']\n",
      "set other 2to 0\n",
      "num of cols: 12\n",
      "encoded: Geography now num of cols: 11\n",
      "NumOfProducts_2\n",
      "set NumOfProducts_2to 1\n",
      "num of cols: 11\n",
      "other vals: ['NumOfProducts_2', 'NumOfProducts_4', 'NumOfProducts_3']\n",
      "set other 3to 0\n",
      "num of cols: 14\n",
      "encoded: NumOfProducts now num of cols: 13\n",
      "Tenure_3\n",
      "set Tenure_3to 1\n",
      "num of cols: 13\n",
      "other vals: ['Tenure_8', 'Tenure_7', 'Tenure_3', 'Tenure_2', 'Tenure_9', 'Tenure_6', 'Tenure_10', 'Tenure_4', 'Tenure_5', 'Tenure_1']\n",
      "set other 10to 0\n",
      "num of cols: 23\n",
      "encoded: Tenure now num of cols: 22\n"
     ]
    }
   ],
   "source": [
    "test_df = preprocess(test_df)\n",
    "test_df[num_cols] = sc.transform(test_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_val = [c for c in test_df.columns if c not in X.columns]\n",
    "col_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = classifier.predict_classes(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
