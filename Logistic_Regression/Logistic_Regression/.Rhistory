training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2]= scale(test_set[,1:2])
library(e1071)
classifier= naiveBayes(x=training_set[-3],
y= training_set$Purchased)
View(classifier)
y_pred= predict(classifier, type='response', newdata= test_set[-3])
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='response', newdata= grid_set)
plot(set[,-3], main='Naive Bayes Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(e1071)
classifier= naiveBayes(x=training_set[-3],
y= training_set$Purchased)
#predict results
y_pred= predict(classifier, type='response', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot training set results
plot_fn(training_set)
#test set visualization
plot_fn(test_set)
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
View(dataset)
View(dataset)
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2]= scale(test_set[,1:2])
classifier= naiveBayes(x=training_set[-3],
y= training_set$Purchased)
y_pred= predict(classifier, type='response', newdata= test_set[-3])
View(test_set)
View(test_set)
y_pred= predict(classifier, type='response', newdata= test_set[-3])
y_pred= predict(classifier, type='class', newdata= test_set[-3])
cm = table(test_set[,3], y_pred)
plot_fn(training_set)
#test set visualization
plot_fn(test_set)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Naive Bayes Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
plot_fn(training_set)
#test set visualization
plot_fn(test_set)
library("rpart", lib.loc="C:/Program Files/R/R-3.4.2/library")
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(rpart)
classifier= rpart(formula = Purchased ~ .,
data= training_set)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot training set results
plot_fn(training_set)
#test set visualization
plot_fn(test_set)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
#training_set[,1:2] = scale(training_set[,1:2])
#test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(rpart)
classifier= rpart(formula = Purchased ~ .,
data= training_set)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot training set results
plot_fn(training_set)
#test set visualization
plot_fn(test_set)
plot(classifier)
text(classifier)
plot_fn<- function(test_set){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = test_set
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='response', newdata= grid_set)
plot(set[,-3], main='Kernel SVM Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
one_hot_encode<- function(test_set){
}
dataset = read.csv("train.csv")
dataset= dataset[,2:13]
dataset$Gender =  sub("^$", "Male", dataset$Gender)
dataset$Married = sub("^$","Yes", dataset$Married)
dataset$Dependents = sub("^$","0", dataset$Dependents)
dataset$Dependents[dataset$Dependents=="3+"]<- "3"
dataset$Self_Employed[dataset$Self_Employed==""]="No"
#dataset.LoanAmount = dataset.LoanAmount.fillna(mean(dataset$LoanAmount, na.rm= TRUE))
dataset$LoanAmount[is.na(dataset$LoanAmount)]= mean(dataset$LoanAmount, na.rm=TRUE)
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)]=median(dataset$Loan_Amount_Term, na.rm=TRUE)
dataset$Credit_History[is.na(dataset$Credit_History)]=mode(dataset$Credit_History)
test_set= read.csv("test.csv")
Loan_ID= test_set[,1]
test_set = test_set[,2:12]
test_set$Gender =  sub("^$", "Male", test_set$Gender)
test_set$Married = sub("^$","Yes", test_set$Married)
test_set$Dependents = sub("^$","0", test_set$Dependents)
test_set$Dependents[test_set$Dependents=="3+"]<- "3"
test_set$Self_Employed[test_set$Self_Employed==""]="No"
#test_set.LoanAmount = test_set.LoanAmount.fillna(mean(test_set$LoanAmount, na.rm= TRUE))
test_set$LoanAmount[is.na(test_set$LoanAmount)]= mean(test_set$LoanAmount, na.rm=TRUE)
test_set$Loan_Amount_Term[is.na(test_set$Loan_Amount_Term)]=median(test_set$Loan_Amount_Term, na.rm=TRUE)
test_set$Credit_History[is.na(test_set$Credit_History)]=mode(test_set$Credit_History)
#imputed missing vals
dataset$Gender= factor(dataset$Gender, levels=c("Female","Male"), labels=c(0,1))
dataset$Married= factor(dataset$Married, levels=c("No","Yes"), labels= c(0,1))
dataset$Education= factor(dataset$Education, levels=c("Not Graduate","Graduate"), labels=c(0,1))
dataset$Self_Employed= factor(dataset$Self_Employed, levels=c("Yes","No"), labels=c(0,1))
dataset$Property_Area = factor(dataset$Property_Area, levels=c("Rural","Urban","Semiurban"), labels=c(1,2,3))
test_set$Gender= factor(test_set$Gender, levels=c("Female","Male"), labels=c(0,1))
test_set$Married= factor(test_set$Married, levels=c("No","Yes"), labels= c(0,1))
test_set$Education= factor(test_set$Education, levels=c("Not Graduate","Graduate"), labels=c(0,1))
test_set$Self_Employed= factor(test_set$Self_Employed, levels=c("Yes","No"), labels=c(0,1))
test_set$Property_Area = factor(test_set$Property_Area, levels=c("Rural","Urban","Semiurban"), labels=c(1,2,3))
#label OneHot encoding
#Feature Scaling
#dataset[,6:9] = scale(dataset[,6:9])
#test_set[,6:9]= scale(test_set[,6:9])
#classifier
library(rpart)
classifier= rpart(formula= Loan_Status~ .,
data= dataset
)
#predict results
Loan_Status= predict(classifier, type='class', newdata= test_set)
results= data.frame(Loan_ID, Loan_Status)
write.csv(results, "results_R.csv", row.names=FALSE)
plot(classifier)
text(classifier)
setwd("D:/Analytics_Vidhya_loan_prediction")
plot_fn<- function(test_set){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = test_set
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='response', newdata= grid_set)
plot(set[,-3], main='Kernel SVM Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
one_hot_encode<- function(test_set){
}
dataset = read.csv("train.csv")
dataset= dataset[,2:13]
dataset$Gender =  sub("^$", "Male", dataset$Gender)
dataset$Married = sub("^$","Yes", dataset$Married)
dataset$Dependents = sub("^$","0", dataset$Dependents)
dataset$Dependents[dataset$Dependents=="3+"]<- "3"
dataset$Self_Employed[dataset$Self_Employed==""]="No"
#dataset.LoanAmount = dataset.LoanAmount.fillna(mean(dataset$LoanAmount, na.rm= TRUE))
dataset$LoanAmount[is.na(dataset$LoanAmount)]= mean(dataset$LoanAmount, na.rm=TRUE)
dataset$Loan_Amount_Term[is.na(dataset$Loan_Amount_Term)]=median(dataset$Loan_Amount_Term, na.rm=TRUE)
dataset$Credit_History[is.na(dataset$Credit_History)]=mode(dataset$Credit_History)
test_set= read.csv("test.csv")
Loan_ID= test_set[,1]
test_set = test_set[,2:12]
test_set$Gender =  sub("^$", "Male", test_set$Gender)
test_set$Married = sub("^$","Yes", test_set$Married)
test_set$Dependents = sub("^$","0", test_set$Dependents)
test_set$Dependents[test_set$Dependents=="3+"]<- "3"
test_set$Self_Employed[test_set$Self_Employed==""]="No"
#test_set.LoanAmount = test_set.LoanAmount.fillna(mean(test_set$LoanAmount, na.rm= TRUE))
test_set$LoanAmount[is.na(test_set$LoanAmount)]= mean(test_set$LoanAmount, na.rm=TRUE)
test_set$Loan_Amount_Term[is.na(test_set$Loan_Amount_Term)]=median(test_set$Loan_Amount_Term, na.rm=TRUE)
test_set$Credit_History[is.na(test_set$Credit_History)]=mode(test_set$Credit_History)
#imputed missing vals
dataset$Gender= factor(dataset$Gender, levels=c("Female","Male"), labels=c(0,1))
dataset$Married= factor(dataset$Married, levels=c("No","Yes"), labels= c(0,1))
dataset$Education= factor(dataset$Education, levels=c("Not Graduate","Graduate"), labels=c(0,1))
dataset$Self_Employed= factor(dataset$Self_Employed, levels=c("Yes","No"), labels=c(0,1))
dataset$Property_Area = factor(dataset$Property_Area, levels=c("Rural","Urban","Semiurban"), labels=c(1,2,3))
test_set$Gender= factor(test_set$Gender, levels=c("Female","Male"), labels=c(0,1))
test_set$Married= factor(test_set$Married, levels=c("No","Yes"), labels= c(0,1))
test_set$Education= factor(test_set$Education, levels=c("Not Graduate","Graduate"), labels=c(0,1))
test_set$Self_Employed= factor(test_set$Self_Employed, levels=c("Yes","No"), labels=c(0,1))
test_set$Property_Area = factor(test_set$Property_Area, levels=c("Rural","Urban","Semiurban"), labels=c(1,2,3))
#label OneHot encoding
#Feature Scaling
#dataset[,6:9] = scale(dataset[,6:9])
#test_set[,6:9]= scale(test_set[,6:9])
#classifier
library(rpart)
classifier= rpart(formula= Loan_Status~ .,
data= dataset
)
#predict results
Loan_Status= predict(classifier, type='class', newdata= test_set)
results= data.frame(Loan_ID, Loan_Status)
write.csv(results, "results_R.csv", row.names=FALSE)
plot(classifier)
text(classifier)
setwd("D:/Udemy_ML/Logistic_Regression/Logistic_Regression")
library("randomForest", lib.loc="C:/Program Files/R/R-3.4.2/library")
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
#training_set[,1:2] = scale(training_set[,1:2])
#test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(randomForest)
classifier= randomForest(x= training_set[-3], y=training_set$Purchased, ntree = 10)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot
plot(classifier)
text(classifier)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
#training_set[,1:2] = scale(training_set[,1:2])
#test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(randomForest)
classifier= randomForest(x= training_set[-3], y=training_set$Purchased, ntree = 10)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot
plot(classifier)
#text(classifier)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
#training_set[,1:2] = scale(training_set[,1:2])
#test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(randomForest)
classifier= randomForest(x= training_set[-3], y=training_set$Purchased, ntree = 500)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot
plot(classifier)
#text(classifier)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
#training_set[,1:2] = scale(training_set[,1:2])
#test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(randomForest)
classifier= randomForest(x= training_set[-3], y=training_set$Purchased, ntree = 100)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot
plot(classifier)
#text(classifier)
plot_fn(training_set)
plot_fn(test_set)
plot_fn<- function(dataset){
#install.packages('ElemStatLearn')
library(ElemStatLearn)
set = dataset
X1= seq(min(set[,1])-1, max(set[,1])+1, by=0.01)
X2= seq(min(set[,2])-1, max(set[,2])+1, by=0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set)= c('Age','EstimatedSalary')
y_grid = predict(classifier, type='class', newdata= grid_set)
plot(set[,-3], main='Decision Tree Classfication', xlab= 'Age', ylab='Estimated Salary',
xlim= range(X1), ylim=range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add=TRUE)
points(grid_set, pch='.', col=ifelse(y_grid==1, 'blue', 'tomato'))
points(set, pch=21, bg= ifelse(set[,3]==1, 'green4', 'red3'))
}
dataset = read.csv("Social_Network_Ads.csv")
dataset = dataset[,3:5]
#encoding the target
dataset$Purchased = factor(dataset$Purchased, levels=c(0,1))
#Split training and test sets
#install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 3/4)
training_set =subset(dataset, split==TRUE)
test_set = subset(dataset, split==FALSE)
#Feature Scaling
training_set[,1:2] = scale(training_set[,1:2])
test_set[,1:2]= scale(test_set[,1:2])
#classifier
library(randomForest)
classifier= randomForest(x= training_set[-3], y=training_set$Purchased, ntree = 100)
#predict results
y_pred= predict(classifier, type='class', newdata= test_set[-3])
#confusion matrix
cm = table(test_set[,3], y_pred)
#plot
plot_fn(training_set)
plot_fn(test_set)
plot(classifier)
#text(classifier)
